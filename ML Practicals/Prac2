
\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{graphicx}
\usepackage[a4paper, margin=2cm, left=3cm]{geometry}
\usepackage{xcolor}
\usepackage{float}
% Custom colors for code highlighting
\definecolor{codebackground}{rgb}{0.95,0.95,0.95}
\definecolor{codekeyword}{rgb}{0,0.5,0.3}
\definecolor{codecomment}{rgb}{0.5,0.5,0.5}
\definecolor{codestring}{rgb}{0.2,0.2,0.8}

% Python code formatting
\lstset{
    language=Python,
    backgroundcolor=\color{codebackground},
    keywordstyle=\color{codekeyword},
    commentstyle=\color{codecomment},
    stringstyle=\color{codestring},
    basicstyle=\ttfamily\small,
    breaklines=true,
    showstringspaces=false,
    numbers=left,
    numberstyle=\tiny\color{codecomment},
    stepnumber=1,
    tabsize=4,
    captionpos=b
}
\documentclass{article}
\usepackage{graphicx}
\usepackage[margin=2.5cm]{geometry}
\usepackage{xcolor}
\usepackage{listings}

\lstset{
  language=Python,
  basicstyle=\ttfamily\small,
  keywordstyle=\color{blue},
  stringstyle=\color{orange},
  commentstyle=\color{green!60!black},
  showstringspaces=false,
  numbers=left,
  numberstyle=\scriptsize,
  stepnumber=1,
  backgroundcolor=\color{gray!10},
  frame=tb,
  captionpos=b,
  breaklines=true,
  breakatwhitespace=false,
  escapeinside={(*@}{@*)},
  tabsize=4
}
\usepackage{ragged2e}
\documentclass[8pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{tikz}
\usetikzlibrary{positioning}
\usepackage{tcolorbox}
\usepackage{amsfonts}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{fancyhdr}
\usepackage{float} % to control float positions
\usepackage{amssymb}
\usepackage[version=4]{mhchem}
\usepackage{stmaryrd}
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage{geometry} % to adjust margins
\geometry{a4paper, margin=1in}
\usepackage[export]{adjustbox}
\graphicspath{ {./images/} }
\geometry{margin=1in} % set margins to 1 inch
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\textit{Atharva Kulkarni \textbf{-Experiment No: 02}}}
\fancyhead[R]{\thepage}
\usepackage{mdframed}
\begin{document}
% %box ....................................................
\begin{tcolorbox}[colback=white!10,height=4.3cm]

\thispagestyle{empty} % remove header from the first page


\makebox[\textwidth]{%
  \begin{tabular}[b]{@{}ll@{}}
    \textbf{BTCOL606: Machine Learning Lab} \\
  \end{tabular}%
  \hfill%
  \begin{tabular}[b]{@{}ll@{}}
    \textbf{(Date: 15/05/2023)}\\
  \end{tabular}%
}

\vspace{1.2cm}
\makebox[\textwidth][c]{\textbf{\LARGE Experiment NO : 02}} % center the experiment number

\vspace{1cm}

\makebox[\textwidth]{%
  \begin{tabular}[t]{@{}ll@{}}

    \textit{Instructor:} Mr.Katkar Atish R. \\
  \end{tabular}%
  \hfill%
  \begin{tabular}[t]{@{}ll@{}}
    \textit{Name:} Atharva Kulkarni, Roll No: CS3266 \\
    
  \end{tabular}%
}

\end{tcolorbox}



\begin{flushleft}

\begin{document}
\begin{justify}
    

\vspace{7mm}

\section*{AIM}
Implement and demonstrate the Decision Tree Algorithm.

\section*{INTRODUCTION TO CANDIDATE ELIMINATION ALGORITHM}
Candidate elimination is a process used in machine learning to narrow down the set of potential algorithms that can be used to solve a particular problem. It involves evaluating each candidate algorithm against a set of criteria and eliminating those that do not meet the criteria.
\vspace{5mm}

The criteria used for candidate elimination may vary depending on the specific problem being addressed but typically include factors such as the algorithm's accuracy, computational efficiency, scalability, interpretability, and ease of implementation. These factors are often prioritized based on the specific requirements of the problem and the available data.
\vspace{5mm}

To begin the candidate elimination process, a set of potential algorithms is identified based on their ability to solve similar problems or their suitability for the specific problem being addressed. Each algorithm is then evaluated against the criteria, and those that do not meet the criteria are eliminated from consideration.
\vspace{5mm}

The remaining candidate algorithms are further evaluated and compared using performance metrics such as accuracy, precision, recall, and F1 score. The algorithm with the best performance on the training and testing data is then chosen as the final model.
\vspace{5mm}

Candidate elimination is an important step in the machine learning process as it helps to narrow down the set of potential algorithms and identify the most suitable option for a particular problem. By carefully evaluating and comparing the available options, it is possible to choose an algorithm that can effectively solve the problem at hand.

\section*{DATASET DESCRIPTION}
A dataset is a collection of data that is used for analysis, modeling, and machine learning. In machine learning, a dataset typically consists of a set of input features and a corresponding target variable, which is the variable that the algorithm is trying to predict.
\vspace{5mm}

To prepare a dataset for machine learning, it is important to clean and preprocess the data to remove any errors or inconsistencies and to transform the input features into a format that can be used by the machine learning algorithm. The dataset is then typically split into a training set and a testing set to evaluate the performance of the algorithm.
\vspace{15mm}
\section*{IMPLEMENTATION CODE FOR DECISION TREE ALGORITHM}
\vspace{5mm}
\begin{lstlisting}
import numpy as np
import pandas as pd

data = pd.read_csv('enjoysport.csv')
concepts = np.array(data.iloc[:, 0:-1])
print("\nInstances are:\n", concepts)
target = np.array(data.iloc[:, -1])
print("\nTarget Values are:", target)


def learn(concepts, target):
    specific_h = concepts[0].copy()
    print("\nInitialization of specific_h and general_h")
    print("\nSpecific Boundary:", specific_h)
    general_h = [["?" for _ in range(len(specific_h))] for _ in range(len(specific_h))]
    print("\nGeneric Boundary:", general_h)

    for i, h in enumerate(concepts):
        print("\nInstance", i+1, "is", h)
        if target[i] == "yes":
            print("Instance is Positive")
            for x in range(len(specific_h)):
                if h[x] != specific_h[x]:
                    specific_h[x] = '?'
                    general_h[x][x] = '?'

        if target[i] == "no":
            print("Instance is Negative")
            for x in range(len(specific_h)):
                if h[x] != specific_h[x]:
                    general_h[x][x] = specific_h[x]
                else:
                    general_h[x][x] = '?'

        print("Specific Boundary after", i+1, "Instance is", specific_h)
        print("Generic Boundary after", i+1, "Instance is", general_h)
        print("\n")

    indices = [i for i, val in enumerate(general_h) if val == ['?', '?', '?', '?', '?', '?']]
    for i in indices:
        general_h.remove(['?', '?', '?', '?', '?', '?'])

    return specific_h, general_h


s_final, g_final = learn(concepts, target)

print("Final Specific_h:", s_final, sep="\n")
print("Final General_h:", g_final, sep="\n")
\end{lstlisting}

\vspace{10mm}
\section*{OUTPUT OF CANDIDATE ELIMINATION ALGORITHM}
\paragraph{\begin{figure}[h]
    \centering
    \includegraphics[width=1.0\textwidth,height=0.48\textheight]{ass2op1.png}
    \includegraphics[width=1.0\textwidth,height=0.2\textheight]{ass2op3.png}
    \caption{Candidate Elimination Output}
\end{figure}
}
\vspace{5mm}

\section*{CONCLUSION}
Candidate elimination is an essential step in the machine learning process as it helps to narrow down the set of potential algorithms and identify the most suitable option for a particular problem. By evaluating each candidate algorithm against a set of criteria, it is possible to eliminate those that do not meet the requirements of the problem and select the best-performing algorithm for the task at hand.

\end{justify}
\end{document}
